{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPgWAbk1Vur2SvTHVcLZ9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abDesgnr/FirstGitHub/blob/master/intro_to_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlK0AMbtat0L",
        "outputId": "393af765-ca36-41da-9a6f-bec336971c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(42, shape=(), dtype=int32)\n",
            "String tensors\n",
            "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n",
            "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n",
            "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n",
            "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n"
          ]
        }
      ],
      "source": [
        "# May 4, 2023\n",
        "# Code example from TensorFlow tutorial:\n",
        "# https://www.tensorflow.org/guide/tensor\n",
        "\n",
        "# TensorFlow Basics\n",
        "# Uncomment print statements to see results\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Tensors are multi-dimensional arrays with a uniform type (called a dtype).\n",
        "\n",
        "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
        "rank_0_tensor = tf.constant(42)\n",
        "print(rank_0_tensor)\n",
        "\n",
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "# print(rank_1_tensor)\n",
        "\n",
        "# If you want to be specific, you can set the dtype (see below) at creation time\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype=tf.float16)\n",
        "#print(rank_2_tensor)\n",
        "\n",
        "# There can be an arbitrary number of\n",
        "# axes (sometimes called \"dimensions\")\n",
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "#print(rank_3_tensor)\n",
        "\n",
        "# convert to numpy array\n",
        "np.array(rank_2_tensor)\n",
        "# or\n",
        "rank_1_tensor.numpy()\n",
        "\n",
        "# Basic math on tensors, including addition, element-wise \n",
        "# multiplication, and matrix multiplication.\n",
        "\n",
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
        "\n",
        "#print(\"Tensor Addition\")\n",
        "#print(tf.add(a, b), \"\\n\")\n",
        "#print(\"Tensor element-wise multiplication\")\n",
        "#print(tf.multiply(a, b), \"\\n\")\n",
        "#print(\"Tensor Matrix multiplication\")\n",
        "#print(tf.matmul(a, b), \"\\n\")\n",
        "\n",
        "# or \n",
        "#print(\"element-wise addition\")\n",
        "#print(a + b, \"\\n\") # element-wise addition\n",
        "#print(\"element-wise multiplication\")\n",
        "#print(a * b, \"\\n\") # element-wise multiplication\n",
        "#print(\"matrix multiplication\")\n",
        "#print(a @ b, \"\\n\") # matrix multiplication\n",
        "\n",
        "# Typically, anywhere a TensorFlow function expects a Tensor as input, \n",
        "# the function will also accept anything that can be converted to a Tensor.\n",
        "aa = [1,2,3]\n",
        "#print(\"this is an array\", aa)\n",
        "tf.convert_to_tensor(aa)\n",
        "\n",
        "# ***********\n",
        "# Tensors have shapes\n",
        "# ***********\n",
        "# Shape: The length (number of elements) of each of the axes of a tensor.\n",
        "# Rank: Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
        "# Axis or Dimension: A particular dimension of a tensor.\n",
        "# Size: The total number of items in the tensor, the product of the shape vector's elements.\n",
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
        "\n",
        "#print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "#print(\"Number of axes:\", rank_4_tensor.ndim)\n",
        "#print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "#print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "#print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "#print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())\n",
        "\n",
        "# To return a tensor Use\n",
        "#print(\"Return a tensor\")\n",
        "#print(\"Rank: \", tf.rank(rank_4_tensor))\n",
        "#print(\"Shape\", tf.shape(rank_4_tensor))\n",
        "tf.shape(rank_4_tensor)\n",
        "\n",
        "# ***********\n",
        "# Indexing\n",
        "# ***********\n",
        "#print(\"\\n\")\n",
        "#print(\"*******Indexing**********\")\n",
        "\n",
        "# Single-axis indexing\n",
        "#TensorFlow follows standard Python indexing rules\n",
        "# indexes start at 0\n",
        "# negative indices count backwards from the end\n",
        "# colons, :, are used for slices: start:stop:step\n",
        "#rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "#print(rank_1_tensor.numpy())  # converts to numpy array\n",
        "#print(rank_1_tensor)\n",
        "\n",
        "# Indexing with a scalar removes the axis:\n",
        "#print(\"First:\", rank_1_tensor[0].numpy())\n",
        "#print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "#print(\"Last:\", rank_1_tensor[-1].numpy())\n",
        "\n",
        "# Indexing with a : slice keeps the axis:\n",
        "#print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "#print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "#print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "#print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "#print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "#print(\"Reversed:\", rank_1_tensor[::-1].numpy())\n",
        "\n",
        "# Multi-axis indexing\n",
        "# Higher rank tensors are indexed by passing multiple indices.\n",
        "# Same rules apply\n",
        "#print(rank_2_tensor.numpy())\n",
        "\n",
        "# Passing an integer for each index, the result is a scalar\n",
        "# Pull out a single value from a 2-rank tensor\n",
        "#print(rank_2_tensor[1, 1].numpy())\n",
        "\n",
        "# You can index using any combination of integers and slices:\n",
        "# Get row and column tensors\n",
        "#print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "#print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "#print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "#print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "#print(\"Skip the first row:\")\n",
        "#print(rank_2_tensor[1:, :].numpy(), \"\\n\")\n",
        "\n",
        "# Here is an example with a 3-axis tensor:\n",
        "#print(\"****Three axix tensor******\")\n",
        "#print(rank_3_tensor.numpy())\n",
        "#print(\"first group of rows and cols\")\n",
        "#print(rank_3_tensor[0, :, :])  # z, row, col\n",
        "#print(\"all row#0 of all groups\")\n",
        "#print(rank_3_tensor[:, 0, :])  # z, row, col\n",
        "#print(\"first col#0 of all groups\")\n",
        "#print(rank_3_tensor[:, :, 0])  # z, row, col\n",
        "#print(\"single scaler\")\n",
        "#print(rank_3_tensor[0, 1, 2])  # z, row, col\n",
        "\n",
        "# ******************\n",
        "# Manipulating Shapes\n",
        "# ******************\n",
        "#print(\"Manipulating Shapes\")\n",
        "# Manipulating Shapes\n",
        "# Reshaping a tensor is of great utility.\n",
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1], [2], [3]])\n",
        "#print(\" x = \", x, \"\\n\")\n",
        "#print(\"x Shape = \", x.shape)\n",
        "\n",
        "# You can convert this object into a Python list, too\n",
        "#print(\"x shape converted to list = \", x.shape.as_list())\n",
        "\n",
        "# You can reshape a tensor to a new shape.\n",
        "# Note that you're passing in a list\n",
        "reshaped = tf.reshape(x, [1, 3])\n",
        "\n",
        "#print(x.shape)\n",
        "#print(reshaped.shape)\n",
        "\n",
        "# The data maintains its layout in memory and a new tensor is created,\n",
        "# with the requested shape, pointing to the same data. TensorFlow uses\n",
        "# C-style \"row-major\" memory ordering, where incrementing the rightmost\n",
        "# index corresponds to a single step in memory.\n",
        "#print(\"rank_3_tensor = \", rank_3_tensor, \"\\n\")\n",
        "\n",
        "# If you flatten a tensor you can see what order it is laid out in memory.\n",
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "#print(\"flatten rank_3_tensor = \", tf.reshape(rank_3_tensor, [-1]), \"\\n\")\n",
        "\n",
        "# Typically the only reasonable use of tf.reshape is to combine or \n",
        "# split adjacent axes (or add/remove 1s). For this 3x2x5 tensor, \n",
        "# reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do,\n",
        "# as the slices do not mix:\n",
        "#print(\"Reshape 3x2X5 rank_3_tensor to (3x2)x5 or 3x(2x5)\")\n",
        "#print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "#print(tf.reshape(rank_3_tensor, [3, -1]))\n",
        "\n",
        "#print(tf.reshape(rank_3_tensor, [2, -1]))  # ab\n",
        "\n",
        "# ****************\n",
        "# Dtypes\n",
        "# ****************\n",
        "#print(\"Dtypes\")\n",
        "# To inspect a tf.Tensor's data type use the Tensor.dtype property.\n",
        "# When creating a tf.Tensor from a Python object you may optionally\n",
        "# specify the datatype. If you don't, TensorFlow chooses a datatype\n",
        "# that can represent your data. TensorFlow converts Python integers\n",
        "# to tf.int32 and Python floating point numbers to tf.float32. Otherwise\n",
        "# TensorFlow uses the same rules NumPy uses when converting to arrays.\n",
        "\n",
        "# You can cast from type to type.\n",
        "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
        "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
        "# Now, cast to an uint8 and lose the decimal precision\n",
        "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
        "#print(the_u8_tensor)\n",
        "\n",
        "# ****************\n",
        "# Broadcasting\n",
        "# ****************\n",
        "#print(\"Broadcasting\")\n",
        "# Broadcasting is a concept borrowed from the equivalent feature in\n",
        "# NumPy{:.external}. In short, under certain conditions, smaller\n",
        "# tensors are \"stretched\" automatically to fit larger tensors when\n",
        "# running combined operations on them.\n",
        "\n",
        "# The simplest and most common case is when you attempt to multiply\n",
        "# or add a tensor to a scalar. In that case, the scalar is broadcast\n",
        "# to be the same shape as the other argument.\n",
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "#print(\"Multiplication with scaler and tensor, same result\")\n",
        "#print(tf.multiply(x, 2))\n",
        "#print(x * y)\n",
        "#print(x * z)\n",
        "\n",
        "# Likewise, axes with length 1 can be stretched out to match the other\n",
        "# arguments. Both arguments can be stretched in the same computation.\n",
        "# In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix\n",
        "# to produce a 3x4 matrix. Note how the leading 1 is optional: The\n",
        "# shape of y is [4].\n",
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "#print(\"x = \", x, \"\\n\")\n",
        "#print(\"y = \", y, \"\\n\")\n",
        "#print(\"x * y = \", tf.multiply(x, y))\n",
        "\n",
        "# *******************\n",
        "# tf.convert_to_tensor\n",
        "# *******************\n",
        "# convert numpy objects to tensors\n",
        "\n",
        "# *******************\n",
        "# RaggedTensor\n",
        "# *******************\n",
        "# A tensor with variable numbers of elements along some axis is\n",
        "# called \"ragged\". Use tf.ragged.RaggedTensor for ragged data.\n",
        "\n",
        "# *******************\n",
        "# String tensors\n",
        "# *******************\n",
        "print(\"String tensors\")\n",
        "# tf.string is a dtype, which is to say you can represent data as\n",
        "# strings (variable-length byte arrays) in tensors.\n",
        "\n",
        "# The strings are atomic and cannot be indexed the way Python strings\n",
        "# are. The length of the string is not one of the axes of the tensor.\n",
        "# See tf.strings for functions to manipulate them.\n",
        "# Here is a scalar string tensor:\n",
        "# Tensors can be strings, too here is a scalar string.\n",
        "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
        "print(scalar_string_tensor)\n",
        "\n",
        "# If you have three string tensors of different lengths, this is OK.\n",
        "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
        "                                 \"Quick brown fox\",\n",
        "                                 \"Lazy dog\"])\n",
        "# Note that the shape is (3,). The string length is not included.\n",
        "print(tensor_of_strings)\n",
        "\n",
        "# In the above printout the b prefix indicates that tf.string dtype\n",
        "# is not a unicode string, but a byte-string. See the Unicode Tutorial\n",
        "# for more about working with unicode text in TensorFlow.\n",
        "\n",
        "# If you pass unicode characters they are utf-8 encoded.\n",
        "tf.constant(\"ü•≥üëç\")\n",
        "\n",
        "# Some basic functions with strings can be found in tf.strings,\n",
        "# including tf.strings.split.\n",
        "# You can use split to split a string into a set of tensors\n",
        "print(tf.strings.split(scalar_string_tensor, sep=\" \"))\n",
        "\n",
        "# ...but it turns into a `RaggedTensor` if you split up a tensor of strings,\n",
        "# as each string might be split into a different number of parts.\n",
        "print(tf.strings.split(tensor_of_strings))\n",
        "\n",
        "# *******************\n",
        "# Sparse tensors\n",
        "# *******************\n",
        "#print(\"Sparse tensors\")\n",
        "# Sometimes, your data is sparse, like a very wide embedding space. \n",
        "# Sparse tensors store values by index in a memory-efficient manner\n",
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "#print(sparse_tensor, \"\\n\")\n",
        "\n",
        "# You can convert sparse tensors to dense\n",
        "#print(tf.sparse.to_dense(sparse_tensor))\n"
      ]
    }
  ]
}